{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cb06b4-f58d-46e0-8f71-b616bcc0512d",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "This final project can be collaborative. The maximum members of a group is 3. You can also work by yourself. Please respect the academic integrity. **Remember: if you get caught on cheating, you get F.**\n",
    "\n",
    "## A Introduction to the competition\n",
    "\n",
    "<img src=\"news-sexisme-EN.jpg\" alt=\"drawing\" width=\"380\"/>\n",
    "\n",
    "Sexism is a growing problem online. It can inflict harm on women who are targeted, make online spaces inaccessible and unwelcoming, and perpetuate social asymmetries and injustices. Automated tools are now widely deployed to find, and assess sexist content at scale but most only give classifications for generic, high-level categories, with no further explanation. Flagging what is sexist content and also explaining why it is sexist improves interpretability, trust and understanding of the decisions that automated tools use, empowering both users and moderators.\n",
    "\n",
    "This project is based on SemEval 2023 - Task 10 - Explainable Detection of Online Sexism (EDOS). [Here](https://codalab.lisn.upsaclay.fr/competitions/7124#learn_the_details-overview) you can find a detailed introduction to this task.\n",
    "\n",
    "You only need to complete **TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist**. To cut down training time, we only use a subset of the original dataset (5k out of 20k). The dataset can be found in the same folder. \n",
    "\n",
    "Different from our previous homework, this competition gives you great flexibility (and very few hints). You can freely determine every component of your workflow, including but not limited to:\n",
    "-  **Preprocessing the input text**: You may decide how to clean or transform the text. For example, removing emojis or URLs, lowercasing, removing stopwords, applying stemming or lemmatization, correcting spelling, or performing tokenization and sentence segmentation.\n",
    "-  **Feature extraction and encoding**: You can choose any method to convert text into numerical representations, such as TF-IDF, Bag-of-Words, N-grams, Word2Vec, GloVe, FastText, contextual embeddings (e.g., BERT, RoBERTa, or other transformer-based models), Part-of-Speech (POS) tagging, dependency-based features, sentiment or emotion features, readability metrics, or even embeddings or features generated by large language models (LLMs).\n",
    "-  **Data augmentation and enrichment**: You may expand or balance your dataset by incorporating other related corpora or using techniques like synonym replacement, random deletion/insertion, or LLM-assisted augmentation (e.g., generating paraphrased or synthetic examples to improve model robustness).\n",
    "-  **Model selection**: You are free to experiment with different models ‚Äî from traditional machine learning algorithms (e.g., Logistic Regression, SVM, Random Forest, XGBoost) to deep learning architectures (e.g., CNNs, RNNs, Transformers), or even hybrid/ensemble approaches that combine multiple models or leverage LLM-generated predictions or reasoning.\n",
    "\n",
    "## Requirements\n",
    "-  **Input**: the text for each instance.\n",
    "-  **Output**: the binary label for each instance.\n",
    "-  **Feature engineering**: use at least 2 different methods to extract features and encode text into numerical values. You may explore both traditional and AI-assisted techniques. Data augmentation is optional.\n",
    "-  **Model selection**: implement with at least 3 different models and compare their performance.\n",
    "-  **Evaluation**: create a dataframe with rows indicating feature+model and columns indicating Precision (P), Recall (R) and F1-score (using weighted average). Your results should have at least 6 rows (2 feature engineering methods x 3 models). Report best performance with (1) your feature engineering method, and (2) the model you choose. Here is an example illustrating how the experimental results table should be presented.\n",
    "\n",
    "| Feature + Model | Sexist (P) | Sexist (R) | Sexist (F1) | Non-Sexist (P) | Non-Sexist (R) | Non-Sexist (F1) | Weighted (P) | Weighted (R) | Weighted (F1) |\n",
    "|-----------------|:----------:|:----------:|:------------:|:---------------:|:---------------:|:----------------:|:-------------:|:--------------:|:---------------:|\n",
    "| TF-IDF + Logistic Regression | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "\n",
    "- **Format of the report**: add explainations for each step (you can add markdown cells). At the end of the report, write a summary for each sections: \n",
    "    - Data Preprocessing\n",
    "    - Feature Engineering\n",
    "    - Model Selection and Architecture\n",
    "    - Training and Validation\n",
    "    - Evaluation and Results\n",
    "    - Use of Generative AI (if you use)\n",
    "\n",
    "## Rules \n",
    "Violations will result in 0 points in the grade: \n",
    "-   `Rule 1 - No test set leakage`: You must not use any instance from the test set during training, feature engineering, or model selection.\n",
    "-   `Rule 2 - Responsible AI use`: You may use generative AI, but you must clearly document how it was used. If you have used genAI, include a section titled ‚ÄúUse of Generative AI‚Äù describing:\n",
    "    -   What parts of the project you used AI for\n",
    "    -   What was implemented manually vs. with AI assistance\n",
    "\n",
    "## Grading\n",
    "\n",
    "The performance should be only evaluated on the test set (a total of 1086 instances). Please split original dataset into train set and test set. The test set should NEVER be used in the training process. The evaluation metric is a combination of precision, recall, and f1-score (use `classification_report` in sklearn). \n",
    "\n",
    "The total points are 10.0. Each team will compete with other teams in the class on their best performance. Points will be deducted if not following the requirements above. \n",
    "\n",
    "If ALL the requirements are met:\n",
    "- Top 25\\% teams: 10.0 points.\n",
    "- Top 25\\% - 50\\% teams: 8.5 points.\n",
    "- Top 50\\% - 75\\% teams: 7.0 points.\n",
    "- Top 75\\% - 100\\% teams: 6.0 points.\n",
    "\n",
    "If your best performance reaches **0.82** or above (weighted F1-score) and follows all the requirements and rules, you will also get full points (10.0 points). \n",
    "\n",
    "## Submission\n",
    "Similar as homework, submit both a PDF and .ipynb version of the report including: \n",
    "- code and experimental results with details explained\n",
    "- combined results table, report and best performance\n",
    "- a summary at the end of the report (please follow the format above)\n",
    "\n",
    "Missing any part of the above requirements will result in point deductions.\n",
    "\n",
    "The due date is **Dec 11, Thursday by 11:59pm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6156cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordsegment in c:\\users\\tucso\\anaconda3\\lib\\site-packages (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is for calling all the imports\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import html\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sentence_transformers import SentenceTransformer\n",
    "!pip install wordsegment\n",
    "from wordsegment import segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "13f3da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING DATA (Expanded Dataset)\n",
      "============================================================\n",
      "Shape: (14000, 4)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "not sexist    0.757286\n",
      "sexist        0.242714\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Split distribution:\n",
      "split\n",
      "train    1.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "TEST DATA (Original Dataset)\n",
      "============================================================\n",
      "Shape: (5279, 4)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "not sexist    0.705247\n",
      "sexist        0.294753\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Split distribution:\n",
      "split\n",
      "train    0.794279\n",
      "test     0.205721\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-16993</td>\n",
       "      <td>Then, she's a keeper. üòâ</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-13149</td>\n",
       "      <td>This is like the Metallica video where the poo...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-13021</td>\n",
       "      <td>woman?</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-14998</td>\n",
       "      <td>Unlicensed day care worker reportedly tells co...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-7228</td>\n",
       "      <td>[USER] Leg day is easy. Hot girls who wear min...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rewire_id  \\\n",
       "0  sexism2022_english-16993   \n",
       "1  sexism2022_english-13149   \n",
       "2  sexism2022_english-13021   \n",
       "3  sexism2022_english-14998   \n",
       "4   sexism2022_english-7228   \n",
       "\n",
       "                                                text       label  split  \n",
       "0                            Then, she's a keeper. üòâ  not sexist  train  \n",
       "1  This is like the Metallica video where the poo...  not sexist  train  \n",
       "2                                             woman?  not sexist  train  \n",
       "3  Unlicensed day care worker reportedly tells co...  not sexist  train  \n",
       "4  [USER] Leg day is easy. Hot girls who wear min...      sexist  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "This cell initializes the random seed loads the data in, shows what it looks like\n",
    "and provides percentages of sexist vs non sexist and train vs test in the data\n",
    "IMPLEMENTED MANUALLY\n",
    "\n",
    "Using expanded training dataset: edos_labelled_data_train_only.csv\n",
    "Test set from original: edos_labelled_data.csv\n",
    "'''\n",
    "RANDOM_SEED = 24\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load expanded training data\n",
    "train_data_file = \"edos_labelled_data_train_only.csv\"\n",
    "df_train_full = pd.read_csv(train_data_file)\n",
    "\n",
    "# Load original data to get test set (for consistent evaluation)\n",
    "test_data_file = \"edos_labelled_data.csv\"\n",
    "df_original = pd.read_csv(test_data_file)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING DATA (Expanded Dataset)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_train_full.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_train_full['label'].value_counts(normalize = True))\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df_train_full['split'].value_counts(normalize = True))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST DATA (Original Dataset)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_original.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_original['label'].value_counts(normalize = True))\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df_original['split'].value_counts(normalize = True))\n",
    "\n",
    "display(df_train_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d4feddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell contains the function to process the input from the data\n",
    "'''\n",
    "# print(df['text'].head(5))\n",
    "\n",
    "# print(df['label'].value_counts())\n",
    "# print(df.isnull().sum())\n",
    "# print(df.duplicated().sum())\n",
    "\n",
    "def split_hashtag(word):\n",
    "    hashtag = word.group(1)\n",
    "    return segment(hashtag)\n",
    "\n",
    "def preprocess_text(s):\n",
    "    if isinstance(s, str):\n",
    "        s = html.unescape(s)\n",
    "        s = re.sub(r'[^a-zA-Z\\s]', '', s)\n",
    "        s = s.strip()\n",
    "        s = s.lower()\n",
    "        s = re.sub(r'http\\S+|www\\S+', '', s)\n",
    "        s = re.sub(r'@(\\w+)', '', s)\n",
    "        s = re.sub(r'#(\\w+)', split_hashtag, s)\n",
    "        s = re.sub(r'\\s+', ' ', s).strip()\n",
    "        return s\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Preprocess training data\n",
    "df_train_full['clean_text'] = df_train_full['text'].apply(preprocess_text)\n",
    "\n",
    "# Preprocess test data\n",
    "df_original['clean_text'] = df_original['text'].apply(preprocess_text)\n",
    "\n",
    "# print(df['clean_text'].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23d146b7-b415-46d8-86ba-2c488ed0fb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data columns: ['rewire_id', 'text', 'label', 'split', 'clean_text']\n",
      "Test data columns: ['rewire_id', 'text', 'label', 'split', 'clean_text']\n",
      "\n",
      "Training set size: 14000\n",
      "Test set size: 1086\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell separates the training and test sets\n",
    "Training data: from edos_labelled_data_train_only.csv (all rows are train)\n",
    "Test data: from edos_labelled_data.csv (test split only)\n",
    "'''\n",
    "\n",
    "# Training data: all rows from train-only file are training data\n",
    "train_df = df_train_full.copy()\n",
    "\n",
    "# Test data: only test split from original file\n",
    "test_df = df_original[df_original['split'] == 'test'].copy()\n",
    "\n",
    "print(\"Training data columns:\", train_df.columns.tolist())\n",
    "print(\"Test data columns:\", test_df.columns.tolist())\n",
    "print(f\"\\nTraining set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ced15b6a-a231-41cd-9288-f8d1aa02d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setup the training data for use later on \n",
    "'''\n",
    "# Training Data\n",
    "X_train = train_df['clean_text']\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Test Data\n",
    "X_test = test_df['clean_text']\n",
    "y_test = test_df['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf36b1d-a814-4b68-967a-019abfd68401",
   "metadata": {},
   "source": [
    "## Feature Engineering Method 1 + 3 Models \n",
    "‚Ä¢ Method 1: TF-IDF\n",
    "\n",
    "‚Ä¢ Models: Logistic Regression, Linear SVC, Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7eb04037-cd15-405d-bab4-1d2ab584608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (14000, 20000)\n",
      "Vocabulary Size: 20000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell will set up TfidVectorizer so we can fit the training data\n",
    "and transform the test data\n",
    "'''\n",
    "vectorizer = TfidfVectorizer(max_features = 20000,\n",
    "                            # includes single and 2 word phrases\n",
    "                            ngram_range = (1, 3), \n",
    "                            # word only gets added if appears more than 2\n",
    "                            min_df = 2,\n",
    "                            # if word appears more than 90% of time then not included\n",
    "                            max_df = .9)\n",
    "\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF shape: \" + str(X_train_vect.shape))\n",
    "print(\"Vocabulary Size: \" + str(len(vectorizer.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "220eb382-6e33-4483-9d67-c8c12b2685e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell is for the helper function I will be using to create the new data frame\n",
    "for the final results. Used Generative AI to come up with this helper function\n",
    "for quickly adding the results of models to a list\n",
    "'''\n",
    "results = []\n",
    "\n",
    "def add_result(feature_name, model_name, y_true, y_pred):\n",
    "    rep = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    row = {\"Feature + Model\": feature_name + \" + \" + model_name}\n",
    "\n",
    "    # class labels only (gets Sexist + Non-Sexist labels only)\n",
    "    classes = [c for c in rep if c not in (\"accuracy\", \"macro avg\", \"weighted avg\")]\n",
    "\n",
    "    # per-class metrics (no f-strings)\n",
    "    for c in classes:\n",
    "        metrics = rep[c]\n",
    "        row[c + \" (P)\"] = metrics[\"precision\"]\n",
    "        row[c + \" (R)\"] = metrics[\"recall\"]\n",
    "        row[c + \" (F1)\"] = metrics[\"f1-score\"]\n",
    "\n",
    "    # weighted metrics\n",
    "    weighted = rep[\"weighted avg\"]\n",
    "    row[\"Weighted (P)\"] = weighted[\"precision\"]\n",
    "    row[\"Weighted (R)\"] = weighted[\"recall\"]\n",
    "    row[\"Weighted (F1)\"] = weighted[\"f1-score\"]\n",
    "\n",
    "    results.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da521595-2184-4b9e-a5c9-99aa8655fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained the TF-IDF + Logistic Regression model!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell trains Logistic Regression model\n",
    "'''\n",
    "\n",
    "logReg = LogisticRegression(max_iter = 500, random_state = RANDOM_SEED)\n",
    "\n",
    "logReg.fit(X_train_vect, y_train)\n",
    "logReg_pred = logReg.predict(X_test_vect)\n",
    "\n",
    "add_result(\"TF-IDF\", \"Logistic Regression\", y_test, logReg_pred)\n",
    "\n",
    "print(\"Trained the TF-IDF + Logistic Regression model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff37afd1-3101-4136-9824-aae7a87e46d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained the TF-IDF + LinearSVC!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell trains the Linear SVC Model\n",
    "'''\n",
    "\n",
    "linSVC = LinearSVC(max_iter = 100, random_state = RANDOM_SEED)\n",
    "\n",
    "linSVC.fit(X_train_vect, y_train)\n",
    "\n",
    "linSVC_pred = linSVC.predict(X_test_vect)\n",
    "\n",
    "add_result(\"TF-IDF\", \"LinearSVC\", y_test, linSVC_pred)\n",
    "\n",
    "print(\"Trained the TF-IDF + LinearSVC!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d33f2a19-daa2-4997-b0b2-ede1b60fe22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained the TF-IDF + Random Forest!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell trains the Random Forest\n",
    "'''\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 200, random_state = RANDOM_SEED, n_jobs = 1)\n",
    "rf.fit(X_train_vect, y_train)\n",
    "pred_rf = rf.predict(X_test_vect)\n",
    "add_result(\"TF-IDF\", \"Random Forest\", y_test, pred_rf)\n",
    "\n",
    "print(\"Trained the TF-IDF + Random Forest!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ca41f4e-edf7-4266-8367-10b4adb88ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9585fb8c8a4ee4965c75bb30168242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a474e88ab894909982d4a9d0845f350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "X_train_sbert = sbert_model.encode(X_train.tolist(), show_progress_bar = True, batch_size = 32)\n",
    "\n",
    "X_test_sbert = sbert_model.encode(X_test.tolist(), show_progress_bar = True, batch_size = 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ccec2ed-c941-4147-9469-a974f4185f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained the SBERT + Logistic Regression!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This model trains SBERT + Logistic Regression \n",
    "'''\n",
    "\n",
    "lr_sbert = LogisticRegression(max_iter = 500, random_state = RANDOM_SEED)\n",
    "lr_sbert.fit(X_train_sbert, y_train)\n",
    "lr_sbert_pred = lr_sbert.predict(X_test_sbert)\n",
    "add_result(\"SBERT\", \"Logistic Regression\", y_test, lr_sbert_pred)\n",
    "\n",
    "print(\"Trained the SBERT + Logistic Regression!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15fe64ab-cfb1-4c49-a967-f367e6a6aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained the SBERT + LinearSVC!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This model trains SBERT + LinearSVC\n",
    "'''\n",
    "\n",
    "linSVC_sbert = LinearSVC(max_iter = 1000, random_state = RANDOM_SEED)\n",
    "linSVC_sbert.fit(X_train_sbert, y_train)\n",
    "linSVC_sbert_pred = linSVC_sbert.predict(X_test_sbert)\n",
    "\n",
    "add_result(\"SBERT\", \"LinearSVC\", y_test, linSVC_sbert_pred)\n",
    "\n",
    "print(\"Trained the SBERT + LinearSVC!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d3715c0-df42-467f-8fb8-d21e3b089ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained the SBERT + Random Forest!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This model trains SBERT + Random Forest\n",
    "'''\n",
    "\n",
    "rf_sbert = RandomForestClassifier(n_estimators = 200, random_state = RANDOM_SEED, n_jobs = 1)\n",
    "rf_sbert.fit(X_train_sbert, y_train)\n",
    "rf_sbert_pred = rf_sbert.predict(X_test_sbert)\n",
    "\n",
    "add_result(\"SBERT\", \"Random Forest\", y_test, rf_sbert_pred)\n",
    "\n",
    "print(\"Trained the SBERT + Random Forest!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e161ad8c-7fbe-431d-9e7b-70431d5cdc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature + Model</th>\n",
       "      <th>not sexist (P)</th>\n",
       "      <th>not sexist (R)</th>\n",
       "      <th>not sexist (F1)</th>\n",
       "      <th>sexist (P)</th>\n",
       "      <th>sexist (R)</th>\n",
       "      <th>sexist (F1)</th>\n",
       "      <th>Weighted (P)</th>\n",
       "      <th>Weighted (R)</th>\n",
       "      <th>Weighted (F1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF + Logistic Regression</td>\n",
       "      <td>0.782477</td>\n",
       "      <td>0.984791</td>\n",
       "      <td>0.872054</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.806678</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>0.747164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF + LinearSVC</td>\n",
       "      <td>0.834076</td>\n",
       "      <td>0.949303</td>\n",
       "      <td>0.887967</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.498316</td>\n",
       "      <td>0.610309</td>\n",
       "      <td>0.821265</td>\n",
       "      <td>0.825967</td>\n",
       "      <td>0.812033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF + Random Forest</td>\n",
       "      <td>0.808091</td>\n",
       "      <td>0.987326</td>\n",
       "      <td>0.888762</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.377104</td>\n",
       "      <td>0.534606</td>\n",
       "      <td>0.838158</td>\n",
       "      <td>0.820442</td>\n",
       "      <td>0.791907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBERT + Logistic Regression</td>\n",
       "      <td>0.799136</td>\n",
       "      <td>0.937896</td>\n",
       "      <td>0.862974</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.485777</td>\n",
       "      <td>0.770315</td>\n",
       "      <td>0.783610</td>\n",
       "      <td>0.759818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBERT + LinearSVC</td>\n",
       "      <td>0.806311</td>\n",
       "      <td>0.939163</td>\n",
       "      <td>0.867681</td>\n",
       "      <td>0.712575</td>\n",
       "      <td>0.400673</td>\n",
       "      <td>0.512931</td>\n",
       "      <td>0.780676</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.770664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SBERT + Random Forest</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.994930</td>\n",
       "      <td>0.844540</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.076677</td>\n",
       "      <td>0.738118</td>\n",
       "      <td>0.733886</td>\n",
       "      <td>0.634544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature + Model  not sexist (P)  not sexist (R)  \\\n",
       "0  TF-IDF + Logistic Regression        0.782477        0.984791   \n",
       "1            TF-IDF + LinearSVC        0.834076        0.949303   \n",
       "2        TF-IDF + Random Forest        0.808091        0.987326   \n",
       "3   SBERT + Logistic Regression        0.799136        0.937896   \n",
       "4             SBERT + LinearSVC        0.806311        0.939163   \n",
       "5         SBERT + Random Forest        0.733645        0.994930   \n",
       "\n",
       "   not sexist (F1)  sexist (P)  sexist (R)  sexist (F1)  Weighted (P)  \\\n",
       "0         0.872054    0.870968    0.272727     0.415385      0.806678   \n",
       "1         0.887967    0.787234    0.498316     0.610309      0.821265   \n",
       "2         0.888762    0.918033    0.377104     0.534606      0.838158   \n",
       "3         0.862974    0.693750    0.373737     0.485777      0.770315   \n",
       "4         0.867681    0.712575    0.400673     0.512931      0.780676   \n",
       "5         0.844540    0.750000    0.040404     0.076677      0.738118   \n",
       "\n",
       "   Weighted (R)  Weighted (F1)  \n",
       "0      0.790055       0.747164  \n",
       "1      0.825967       0.812033  \n",
       "2      0.820442       0.791907  \n",
       "3      0.783610       0.759818  \n",
       "4      0.791897       0.770664  \n",
       "5      0.733886       0.634544  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL: TF-IDF + LinearSVC\n",
      "Weighted F1: 0.8120\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "creates the final table\n",
    "'''\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "best = None\n",
    "best_f1 = 0\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    if (row['Weighted (F1)'] > best_f1):\n",
    "        best_f1 = row['Weighted (F1)']\n",
    "        best = row\n",
    "\n",
    "print(\"BEST MODEL: \" + best[\"Feature + Model\"])\n",
    "print(\"Weighted F1: \" + format(best[\"Weighted (F1)\"], \".4f\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8675e93",
   "metadata": {},
   "source": [
    "## Experimental Results\n",
    "\n",
    "(A table detailed model performance on the test set with at least 6 rows. Report the best performance.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f84b04",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "### 1. Data Preprocessing\n",
    "\n",
    "\n",
    "### 2. Feature Engineering\n",
    " \n",
    "\n",
    "### 3. Model Selection and Architecture\n",
    "\n",
    "\n",
    "### 4. Training and Validation\n",
    "\n",
    "\n",
    "### 5. Evaluation and Results\n",
    "\n",
    "\n",
    "### 6. Use of Generative AI (if you use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242656d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
